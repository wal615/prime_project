---
title: "An introduction to parallel computation using foreach package"
author: | 
  | Xuelong Wang  
  | University of Illinois at Chicago
  | Department of Statistics
  
date: "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: bibliography.bib
output:
  beamer_presentation: default
  ioslides_presentation: default
  slidy_presentation: default
---


---
nocite: | 
  @ref1, @ref2, @ref3, @ref4
...


```{r, echo = FALSE, message = FALSE}
library(parallel)
library(doParallel)
library(foreach)
options(width = 40)
```

# What kind of parallel computation
## Perfectly parallel computation (Embarrassingly parallel computation)

- There is little or no effort needed to separate the problem into a number of parallel tasks
- Bootstrapping
- cross-validation
- grid search, etc
    
# A basic parctice of parallel computation 

## Hardware requirment
  - Single cluster (your own laptop)
  - Only requests multiple (cores) CPUs

## Package requirment 
```{r, eval=FALSE}
library(doParallel)
library(foreach)
library(parallel)
library(iterators)
```
 

# *foreach* package

## An easy and starndard way of parallel comuptation

- Can run a for-loop task as a set of of parallel tasks 

- Take care of the communication between the tasks (cores)

# Getting start Example

Calculate the sum of the square $$\sum_{i=1}^{10000}\sum_{j=1}^{i} j^2$$
There is a warning saying the loop ran sequentially   
To run the loop parallelly,  we need to register parallel backends. 

```{r, tidy = TRUE, fill =TRUE, collapse=TRUE}
system.time(foreach(i=1:10000) %do% sum((1:i)^2))[3]
system.time(foreach(i=1:10000) %dopar% sum((1:i)^2))[3]
```

# R *foreach*
## Parallel backends

```{r, tidy = TRUE, fill =TRUE, collapse=TRUE}
registerDoParallel()
```

*registerDoParallel()* is used to register cores to parallel computation 

```{r, tidy = TRUE, fill =TRUE, collapse=TRUE}
system.time(foreach(i=1:10000) %do% sum(sqrt(1:i)))[3]
system.time(foreach(i=1:10000) %dopar% sum(sqrt(1:i)))[3]
```

# R *foreach*
## Getting more information of Parallel backends

```{r, tidy = TRUE, fill =TRUE, collapse=TRUE}
# how many cores are being used
getDoParWorkers()
# changing back to sequential loop
registerDoSEQ()  
getDoParWorkers()
```

# R *foreach*
## Getting more information of Parallel backends

```{r, tidy = TRUE, fill =TRUE, collapse=TRUE}
# Check how many cores are avaiable
detectCores()
# Setting foreach to use 3 cores
registerDoParallel(cores=3)  
getDoParWorkers()
getDoParName()
```
- *doMC* is built on a packaged called *multicore* (for UNIX-like system),  which is used to create a cluster for communication between cores.


# Bootstraping example
```{r, echo=FALSE, eval=TRUE}
x <- iris[which(iris[,5] != "setosa"), c(1,5)]
dopar <- system.time(r <- foreach(i = 1:10000) %dopar% {
  ind <- sample(100, 100, replace=TRUE)
  result1 <- glm(x[ind,2]~x[ind,1],
                 family=binomial(logit))
  coefficients(result1)
  })[3]
do <- system.time(r <- foreach(i = 1:10000) %do% {
  ind <- sample(100, 100, replace=TRUE)
  result1 <- glm(x[ind,2]~x[ind,1],
                 family=binomial(logit))
  coefficients(result1)
  })[3]
```
```{r, tidy = TRUE, fill =TRUE, collapse=TRUE}
dim(x)
r <- foreach(i = 1:10000) %dopar% {
  ind <- sample(100, 100, replace=TRUE)
  result1 <- glm(x[ind,2]~x[ind,1], family=binomial(logit))
  coefficients(result1)
  }
r[1]
class(r)
```
- Escaped time for using  `r getDoParWorkers()` cores is `r dopar` seconds
- Escaped time for using single core is `r do` seconds

# .Combine Option
```{r, tidy = TRUE, fill =TRUE, collapse=TRUE}
r <- foreach(i = 1:100, .combine = cbind) %dopar% {
  ind <- sample(100, 100, replace=TRUE)
  result1 <- glm(x[ind,2]~x[ind,1], family=binomial(logit))
  coefficients(result1)
  }
class(r)
```
- Specify the way of combining the foreach result 
- *.combine* can also take function like 'c', 'rbind' or even '+'

# Warnings and tips

## Simple problems may not be benifted by foreach 
  - Communication between cores also takes time

## Registering too many cores may lead to memory issues
  - *foreach* will copy all the related data for each task
  - Iterator may reduce the usage of memory

## Use tools to check if foreach runs parallely
  - Windows Task Mananger
  - Linux *top* command 

----

![Donâ€™t waste another second, start parallelizing your computations today](https://i2.wp.com/gforge.se/wp-content/uploads/2015/02/Horse_power_smudge_9000.jpg)

  
# Reference

